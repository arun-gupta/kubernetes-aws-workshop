= Install kubernetes cluster on AWS using kops
:toc:

This tutorial will walk you through how to install kubernetes cluster using kops.

== Install kops and kubectl on your PC

    brew update && install kops
    curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.goo\
    gleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl
    chmod +x ./kubectl
    sudo mv ./kubectl /usr/local/bin/kubectl

== IAM user permission

Make sure the latest version of http://docs.aws.amazon.com/cli/latest/userguide/installing.html[AWS CLI]
is installed. User permissions being used must have these http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies.html[IAM policies] attached

    AmazonEC2FullAccess
    AmazonRoute53FullAccess
    AmazonS3FullAccess
    IAMFullAccess
    AmazonVPCFullAccess

Please review this link for additional info on IAM permission:
https://github.com/kubernetes/kops/blob/master/docs/aws.md#setup-iam-user

== Create bucket to store k8s config

    aws s3api create-bucket --bucket kubernetes-aws-config
    # enable versioning and export
    aws s3api put-bucket-versioning --bucket kubernetes-aws-config --versioning-configuration\
    Status=Enabled
    export KOPS_STATE_STORE=s3://kubernetes-aws-config

== Create hosted zone on Route53

If you own Route53 domain name, download https://github.com/stedolan/jq/wiki/Installation[jq]
and run this command:

    ID=$(uuidgen) && aws route53 create-hosted-zone --name kubernetes-aws.io \
    --caller-reference $ID | jq .DelegationSet.NameServers

See other means of creating DNS: https://github.com/kubernetes/kops/blob/master/docs/aws.md#configure-dns

If you don't own domain name, you can create custom domain using Route53's private hosted zone
you need to provide VPC info to run this command. See below how to <<Create VPC (Optional)>>

    ID=$(uuidgen) && aws route53 create-hosted-zone --name k8s-aws.internal \
    --vpc VPCRegion=us-east-1,VPCId=$VPCID --caller-reference $ID \
    | jq .DelegationSet.NameServers

== Create kubernetes cluster

    kops create cluster --name cluster01.kubernetes-aws.io --state s3://kubernetes-aws-config
    # review cluster info and make changes if necessary (for ex, subnet sizing)
    kops get cluster
    kops edit cluster cluster01.kubernetes-aws.io
    # update and commit
    kops update cluster cluster01.kubernetes-aws.io --yes

More options for creating k8s clusters are listed below

Create cluster with multi master, multi node and multi-az configuration

    kops create cluster --name cluster02.kubernetes-aws.io --master-count 3 --master-zones\
    us-east-1a,us-east-1b --node-count 5 --zones us-east-1a,us-east-1b,us-east-1c \
     --state s3://kubernetes-aws-config

Create cluster with Route53 private hosted zone and VPC

    kops create cluster --dns private --name cluster03.k8s-aws.internal --zones us-east-1a,\
    us-east-1b --state s3://kubernetes-aws-config --vpc $VPCID --network-cidr 10.1.0.0/16\
     --ssh-public-key $mypubkey

== Validate cluster

    kops validate cluster

The following is the output for cluster with 3 master nodes and 6 worker nodes using Route53
    private hosted zone

    Using cluster from kubectl context: cluster03.k8s-aws.internal
    Validating cluster cluster03.k8s-aws.internal
    INSTANCE GROUPS
    NAME			ROLE	MACHINETYPE	MIN	MAX	SUBNETS
    master-us-east-1a-1	Master	m3.medium	1	1	us-east-1a
    master-us-east-1a-2	Master	m3.medium	1	1	us-east-1a
    master-us-east-1b-1	Master	m3.medium	1	1	us-east-1b
    nodes			Node	t2.medium	6	6	us-east-1a,us-east-1b,us-east-1c

    NODE STATUS
    NAME				ROLE	READY
    ip-10-10-105-101.ec2.internal	node	True
    ip-10-10-127-80.ec2.internal	node	True
    ip-10-10-33-192.ec2.internal	master	True
    ip-10-10-36-230.ec2.internal	master	True
    ip-10-10-45-69.ec2.internal	node	True
    ip-10-10-51-111.ec2.internal	node	True
    ip-10-10-71-96.ec2.internal	node	True
    ip-10-10-87-59.ec2.internal	node	True
    ip-10-10-93-160.ec2.internal	master	True
    Your cluster cluster03.k8s-aws.internal is ready

TIP: You may need to add cluster API endpoints into your hosts file (/etc/hosts) if you use Route53
private hosted zone along with VPC option.

== Create VPC (Optional)

     VPCID=`aws ec2 create-vpc --cidr-block 10.1.0.0/16 --region us-east-1 --query 'Vpc.VpcId' --output text`
     # modify dns hostname resolution for the VPC
     aws ec2 modify-vpc-attribute --vpc-id $VPCID --enable-dns-hostnames "{\"Value\":true}"
     # create internet gateway and attach it to VPC
     IGW=`aws ec2 create-internet-gateway --region us-east-1 --query 'InternetGateway.InternetGatewayId' --output text`
     aws ec2 attach-internet-gateway --internet $IGW --vpc $VPCID --region us-east-1

== Terminate cluster

    kops delete cluster cluster01.kubernetes-aws.io --state s3://kubernetes-aws-config --yes
    # Find Route53 hosted zone ID from the console or via CLI and delete hosted zone
    aws route53 delete-hosted-zone --id Z1234567890ABC
    # Delete VPC if you created earlier
    aws ec2 detach-internet-gateway --internet $IGW --vpc $VPCID --region us-east-1
    aws ec2 delete-internet-gateway --internet-gateway-id $IGW
    aws ec2 delete-vpc --vpc-id $VPCID

This doc is related to https://github.com/arun-gupta/kubernetes-aws-workshop/issues/5
